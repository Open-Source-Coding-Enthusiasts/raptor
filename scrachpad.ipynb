{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import SpacyTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "with open('sample.txt', 'r') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = SpacyTextSplitter(max_length=len(text),\n",
    "                             separator='.',\n",
    "                             chunk_size=100,\n",
    "                             chunk_overlap=0)\n",
    "\n",
    "texts = splitter.split_text(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import CohereEmbeddings\n",
    "\n",
    "embeddings = CohereEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs = embeddings.embed_documents(texts[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "d = {}\n",
    "for i, embedding_vec in enumerate(embedded_docs):\n",
    "    d[i] = [texts[i], embedding_vec]\n",
    "\n",
    "df = pd.DataFrame(d).T.rename(columns={1:'leaf_embeddings',0:'leaf_text'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "model = KMeans(n_clusters=3, random_state=42)\n",
    "model = model.fit(df['leaf_embeddings'].tolist())\n",
    "df['cluster_1'] = model.labels_\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarize Clusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Cohere\n",
    "\n",
    "llm = Cohere(temperature=0.1)\n",
    "\n",
    "prompt = \"\"\"\n",
    "            You are an AI assitant. You are helping with the task of summarization. \n",
    "            Below you will find a text fragment, Tell me what is this about. Be as concise as possible with your summary.\n",
    "\n",
    "            ANSWER ONLY WITH THE SUMMARY. DO NOT INCLUDE THE ORIGINAL TEXT, DO NOT ASK QUESTIONS OR SUGGESTIONS.\n",
    "            ###\n",
    "\n",
    "            {paragraph}\"\"\"\n",
    "\n",
    "\n",
    "cluster_summaries = {}\n",
    "for i in df['cluster_1'].unique():\n",
    "    cluster_contents = ','.join(df[df['cluster_1'] == i]['leaf_text'].tolist())\n",
    "    cluster_summary = llm.invoke(prompt.format(paragraph=cluster_contents))\n",
    "    cluster_summaries[i] = cluster_summary\n",
    "\n",
    "df['cluster_1_summary'] = df['cluster_1'].map(cluster_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summaries_embedded = {}\n",
    "for summary in df['cluster_1_summary'].unique():\n",
    "    embedded_summary = embeddings.embed_documents([summary])\n",
    "    cluster_summaries_embedded[summary] = embedded_summary[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embed Cluster Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster_1_summary_embeddings'] = df['cluster_1_summary'].map(cluster_summaries_embedded)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KMeans(n_clusters=2, random_state=42)\n",
    "model = model.fit(df['cluster_1_summary_embeddings'].tolist())\n",
    "df['cluster_2'] = model.labels_\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summaries = {}\n",
    "for i in df['cluster_2'].unique():\n",
    "    cluster_contents = ','.join(df[df['cluster_2'] == i]['cluster_1_summary'].tolist())\n",
    "    cluster_summary = llm.invoke(prompt.format(paragraph=cluster_contents))\n",
    "    cluster_summaries[i] = cluster_summary\n",
    "\n",
    "df['cluster_2_summary'] = df['cluster_2'].map(cluster_summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summaries_embedded = {}\n",
    "for summary in df['cluster_2_summary'].unique():\n",
    "    embedded_summary = embeddings.embed_documents([summary])\n",
    "    cluster_summaries_embedded[summary] = embedded_summary[0]\n",
    "df['cluster_2_summary_embeddings'] = df['cluster_2_summary'].map(cluster_summaries_embedded)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "prompt = \"\"\"\n",
    "        You are an AI assitant. You are helping with the task of summarization. \n",
    "        Below you will find a text fragment, Tell me what is this about. Be as concise as possible with your summary.\n",
    "\n",
    "        ANSWER ONLY WITH THE SUMMARY. DO NOT INCLUDE THE ORIGINAL TEXT, DO NOT ASK QUESTIONS OR SUGGESTIONS.\n",
    "        ###\n",
    "\n",
    "        {paragraph}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_and_summarize(texts, n_summaries, embeddings, llm, prompt, n_clusters=5):\n",
    "    embedded_docs = embeddings.embed_documents(texts)\n",
    "    d = {i: [texts[i], embedding_vec] for i, embedding_vec in enumerate(embedded_docs)}\n",
    "\n",
    "    df = pd.DataFrame(d).T.rename(columns={1:'embeddings',0:'text'})\n",
    "\n",
    "    decrement = (n_clusters - 2) / (n_summaries - 1) if n_summaries > 1 else 0\n",
    "\n",
    "    prev_clusters = n_clusters\n",
    "    for i in range(n_summaries):\n",
    "        model = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        model = model.fit(df['embeddings'].tolist())\n",
    "        df[f'cluster_{i+1}'] = model.labels_\n",
    "\n",
    "        cluster_summaries = {}\n",
    "        for j in df[f'cluster_{i+1}'].unique():\n",
    "            cluster_contents = ','.join(df[df[f'cluster_{i+1}'] == j]['text'].tolist())\n",
    "            cluster_summary = llm.invoke(prompt.format(paragraph=cluster_contents))\n",
    "            cluster_summaries[j] = cluster_summary.content\n",
    "\n",
    "        df[f'cluster_{i+1}_summary'] = df[f'cluster_{i+1}'].map(cluster_summaries)\n",
    "\n",
    "        cluster_summaries_embedded = {}\n",
    "        for summary in df[f'cluster_{i+1}_summary'].unique():\n",
    "            embedded_summary = embeddings.embed_documents([summary])\n",
    "            cluster_summaries_embedded[summary] = embedded_summary[0]\n",
    "\n",
    "        df[f'cluster_{i+1}_summary_embeddings'] = df[f'cluster_{i+1}_summary'].map(cluster_summaries_embedded)\n",
    "\n",
    "        n_clusters = max(2, round(n_clusters - decrement))\n",
    "        if n_clusters == prev_clusters:\n",
    "            break\n",
    "        prev_clusters = n_clusters\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1,model='gpt-3.5-turbo-16k')\n",
    "embeddings = OpenAIEmbeddings()\n",
    "\n",
    "df2 = cluster_and_summarize(texts[:20], 5, embeddings, llm, prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Documents objects with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text',\n",
       " 'cluster_1_summary',\n",
       " 'cluster_2_summary',\n",
       " 'cluster_3_summary',\n",
       " 'cluster_4_summary']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "text_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.document import Document\n",
    "\n",
    "def preprocess_texts(df):\n",
    "    text_cols = ['text'] + [col for col in df.columns if 'summary' == col.split('_')[-1]]\n",
    "    docs = []\n",
    "    for index, values in df[text_cols].iterrows():\n",
    "        for i in range(len(text_cols)):\n",
    "            try:\n",
    "                metadata = {'cluster_summary': values.iloc[i+1],\n",
    "                            'node_position': i,}\n",
    "            except IndexError:\n",
    "                metadata = {'cluster_summary': 'root node',\n",
    "                            'node_position': 'root node',}\n",
    "            doc = Document(values.iloc[0], metadata=metadata)\n",
    "            docs.append(doc)\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from langchain_community.vectorstores import Qdrant\n",
    "from langchain.vectorstores.base import VectorStore\n",
    "\n",
    "client = QdrantClient('http://localhost:6333')\n",
    "vector_db = Qdrant(client,collection_name='test_collection',embeddings=embeddings)\n",
    "\n",
    "async def embed_docs(vector_db: VectorStore, docs, embeddings) -> None:\n",
    "    await vector_db.afrom_documents(docs, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "await embed_docs(vector_db, preprocess_texts(df2), embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
